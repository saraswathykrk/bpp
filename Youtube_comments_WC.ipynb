{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Youtube_comments_WC.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saraswathykrk/ml_work/blob/main/Youtube_comments_WC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2gw2BhLZyuq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "baf0ddde-095c-43c4-df8b-f065be0ce01b"
      },
      "source": [
        "i = []\n",
        "while(True):\n",
        "  i.append('a')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cc018406b551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02YBX_MbKBY7"
      },
      "source": [
        "Install the relevant libraries \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd5Lek5yKAbU"
      },
      "source": [
        "%%capture\n",
        "!pip install google-api-python-client\n",
        "!pip install pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTbtIT2WJ9s0"
      },
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hMUOUyiAq9y"
      },
      "source": [
        "There are many resources available with the API which can be retrieved from the youtube.They include: \n",
        "\n",
        "*   **Video** It contains information about the videos of youtube. Information like total number of videos including their total likes/dislikes, comments and subscriber etc.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXk1WqdcPuZP"
      },
      "source": [
        "youTubeApiKey=\"AIzaSyAEvcG3jPyVbSSz-3_YYS-3jDWwi29pIC0\"\n",
        "youtube=build('youtube','v3',developerKey=youTubeApiKey)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fziNw5od_cbn"
      },
      "source": [
        "In the next step we will try to find out the video id and the related information using the <b>display name</b> of video at youtube.<br>\n",
        "likewise I am using <b>DIY terrace gardening</b><br>\n",
        "\n",
        "Here we are going to find the details of channel resources.There are different properties, which can be used i.e. information corresponding to that property like \n",
        "* **snippet** which provide the basic details about the channel\n",
        "* **Statistics** provides the statistics of the channel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKzqEzKtjZ86"
      },
      "source": [
        "## Resource - **Video** \n",
        "### Property - **Snippets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCmCduOwPkrj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "0a196c1e-9873-4c58-99eb-7a4e49a06644"
      },
      "source": [
        "snippets = youtube.search().list(part=\"snippet\", type=\"video\", q=\"DIY terrace farming\", maxResults=500,regionCode = 'IN').execute()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-aa0b2f2c2208>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msnippets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myoutube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"snippet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"video\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"DIY terrace farming\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxResults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregionCode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'IN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'youtube' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJXNoqF_Ehgx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "a131ea40-ac3d-4168-ba3a-5b38e7ae8944"
      },
      "source": [
        "snippets[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8243e47c3ffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msnippets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'snippets' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H9F0ZdoF8Am"
      },
      "source": [
        "print(snippets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULa5kXKXEZ7g"
      },
      "source": [
        "for item in snippets:\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qO54bAeEdUs"
      },
      "source": [
        "for key,value in snippets.items():\n",
        "  print(key,\"*************\",value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzSSAP3RGMqb"
      },
      "source": [
        "for i in snippets['items']:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNROVQrrhF9W"
      },
      "source": [
        "Now we will retrieved the complete details of all videos individually uploaded on the channel- youtube and will save in dataframe as csv file.<br>\n",
        "including the:\n",
        "* videoTitle\n",
        "* videoID\n",
        "* likedCount\n",
        "* dislikedCount\n",
        "* viewCount\n",
        "* commentCount\n",
        "* publishedAt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eg0eJrFzl2G"
      },
      "source": [
        "video_dict = {}\n",
        "vid_list = []\n",
        "for i in snippets['items']:\n",
        "  # print(i['id']['videoId'])\n",
        "  print(i['snippet']['publishedAt'],i['snippet']['title'],i['snippet']['publishTime'])\n",
        "  vid_list = [i['snippet']['publishedAt'],i['snippet']['title'],i['snippet']['publishTime']]\n",
        "  print(vid_list)\n",
        "  video_dict[i['id']['videoId']] = vid_list\n",
        "video_id_list = list(video_dict.keys())\n",
        "print(video_id_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mjnUgnYHbLv"
      },
      "source": [
        "From the above blocks of code we can see that by using property **snippets**  we got all the information related with the channel,actually information of all the related channels including **channelId, title, description,thumbnails and publishTime**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ynMvPLRGC0g"
      },
      "source": [
        "## Now extract the videoId,of the first channel in list, as follows: \n",
        "\n",
        "videoId = snippets['items'][0]['id']['videoId']\n",
        "\n",
        "print(\"Video ID of the first video is \"+ videoId)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5jpiKwqgoaA"
      },
      "source": [
        "print(\"Video \"+snippets['items'][0]['snippet']['title'] +\" is published at \"+snippets['items'][0]['snippet']['publishedAt'])\n",
        "print(\"Here is the description available at the video page on youtube \\n\")\n",
        "print(snippets['items'][0]['snippet']['description'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4Rskz3yjmum"
      },
      "source": [
        "### Property - **Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfebVYi4-pqQ"
      },
      "source": [
        "# stats = youtube.videos().list(part=\"statistics\", id = videoId).execute()\n",
        "stats = youtube.videos().list(part=\"statistics\", id = video_id_list #id = ['lfgYr9mhhqk', 'I7hNEubPdGo'] \n",
        "                              ).execute()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw4gi-Y2I6r_"
      },
      "source": [
        "stats['items']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5B__KLmIqaw"
      },
      "source": [
        "stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twyrAUX7IxA2"
      },
      "source": [
        "for item in stats['items']:\n",
        "  print(item)\n",
        "# for i in stats.items():\n",
        "#   print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcSYW47ToGg4"
      },
      "source": [
        "video_dict = {}\n",
        "vid_list = []\n",
        "sub_dict = {}\n",
        "for i in snippets['items']:\n",
        "  # print(i['id']['videoId'])\n",
        "  # print(i['snippet']['publishedAt'],i['snippet']['title'],i['snippet']['publishTime'])\n",
        "  # vid_list = [i['snippet']['publishedAt'],i['snippet']['title'],i['snippet']['publishTime']]\n",
        "  # print(vid_list)\n",
        "  sub_dict = {'videoId':i['id']['videoId'],'publishedAt':i['snippet']['publishedAt'],'title':i['snippet']['title'],'publishTime':i['snippet']['publishTime']}\n",
        "  # video_dict[i['id']['videoId']] = vid_list\n",
        "  # print(sub_dict['videoID'])\n",
        "  video_dict[i['id']['videoId']] = sub_dict\n",
        "\n",
        "print(video_dict)\n",
        "\n",
        "new_video_dict = {}\n",
        "for item in stats['items']:\n",
        "  # print(item['id'],item['statistics']['viewCount'],item['statistics']['likeCount'],item['statistics']['dislikeCount'],item['statistics']['favoriteCount'],item['statistics']['commentCount'])\n",
        "  try:\n",
        "    new_video_dict = {'videoId':item['id'],'viewCount':item['statistics']['viewCount'],\n",
        "                      'likeCount':item['statistics']['likeCount'],\n",
        "                      'dislikeCount':item['statistics']['dislikeCount'],\n",
        "                      'favoriteCount':item['statistics']['favoriteCount'],\n",
        "                      'commentCount':item['statistics']['commentCount']}\n",
        "    # print(new_video_dict)\n",
        "    \n",
        "  except:\n",
        "    print('Error'+item['id'])\n",
        "    new_video_dict = {}\n",
        "  \n",
        "  video_dict[item['id']].update(new_video_dict)\n",
        "\n",
        "print(video_dict)\n",
        "\n",
        "from google.colab import files\n",
        "df_new_t = pd.DataFrame.from_dict(video_dict)\n",
        "df_new = df_new_t.T\n",
        "df_new.to_csv('Videos.csv', index=False) \n",
        "files.download('Videos.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gOPoD3wJEF7"
      },
      "source": [
        "In the following cell we will see the statistics of particular channel which we acquired using API, which includes **total subscribers, videoCounts, viewCounts**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_4-ejTJI_qz"
      },
      "source": [
        "print(\"Total Number of Views of \"+snippets['items'][0]['snippet']['title'] + \" is \"+stats['items'][0]['statistics']['viewCount'])\n",
        "print(\"Total Number of Dislikes of \"+snippets['items'][0]['snippet']['title'] + \" is \"+stats['items'][0]['statistics']['dislikeCount'])\n",
        "print(\"Total Number of Likes of \"+snippets['items'][0]['snippet']['title'] + \" is \"+stats['items'][0]['statistics']['likeCount'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYSorWCUjtV-"
      },
      "source": [
        "### Property - **ContentDetails**\n",
        "\n",
        "In this we will get the details of all the videos related to that channel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMiTEhb3oGdY"
      },
      "source": [
        "### Property - **Status**\n",
        "\n",
        "It includes the information about the privacy status of the channel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1cdlsOn3xG5"
      },
      "source": [
        "**nextPageToken** it will be used as the value of pageToken parameter to retrieve the previous page details. It will be useful as when we will be retireve the playlistItems in the above cell then there is maxium limit of 50 Items i.e. only retrieve the 50 items per search.<br>\n",
        "So to retrieve the information of all videos, we will be using while loop and nextPageToken as inthe following cell:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky613WIpzxBi"
      },
      "source": [
        "# declare an empty list where we will store the information retrievd of all the uploaded videos on the channel\n",
        "\n",
        "allVideos = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i7svbbI2HlT"
      },
      "source": [
        "nextPage_token = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYEtwXxN5TKL"
      },
      "source": [
        "while 1:\n",
        "  # res = youtube.playlistItems().list(playlistId = UploadId,maxResults = 50,part = 'snippet',pageToken = nextPage_token).execute()\n",
        "  snippets = youtube.search().list(part=\"snippet\", type=\"video\", q=\"DIY terrace farming\", maxResults=50,regionCode = 'IN',order = 'viewCount', pageToken = nextPage_token).execute()\n",
        "\n",
        "  allVideos += snippets['items']\n",
        "\n",
        "  nextPage_token = snippets.get('nextPageToken')\n",
        "\n",
        "  if nextPage_token is  None:\n",
        "    break\n",
        "\n",
        "print(allVideos)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRz2RNgDC5uH"
      },
      "source": [
        "len(allVideos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF-RttXr-YBs"
      },
      "source": [
        "Now all the information related to all the uploaded videos on this youtube channel got saved inthis list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX9Q0yvz-jFc"
      },
      "source": [
        "print(\"total number of videos uploaded on this topic is \", len(allVideos))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOFG2BWL1udd"
      },
      "source": [
        "snippets['items'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_Mqw5TY2AR8"
      },
      "source": [
        "allVideos[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoaBTc9R7rfP"
      },
      "source": [
        "allVideos[0]['id']['videoId']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7OcwEfb965B"
      },
      "source": [
        "print(\"Display the information related to the latest uploaded video on the channel\\n\")\n",
        "print(\"Title of latest video uploaded: \"+ allVideos[0]['snippet']['title'])\n",
        "print(\"The latest video uploaded on date: \"+allVideos[0]['snippet']['publishedAt'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le9D_FKmBAVV"
      },
      "source": [
        "### Retrieve the videoIDs of all the videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cvPPi3WAb_R"
      },
      "source": [
        "video_ids = list(map(lambda x:x['id']['videoId'], allVideos))\n",
        "print(len(video_ids))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pFvDxdXHRtQ"
      },
      "source": [
        "stats = []\n",
        "for i in range(0, len(video_ids), 40):\n",
        "  res = (youtube).videos().list(id=','.join(video_ids[i:i+40]),part='statistics').execute()\n",
        "  stats += res['items']\n",
        "print(stats)\n",
        "\n",
        "contents = []\n",
        "for i in range(0, len(video_ids), 40):\n",
        "  res = (youtube).videos().list(id=','.join(video_ids[i:i+40]),part='contentDetails').execute()\n",
        "  contents += res['items']\n",
        "print(contents)\n",
        "\n",
        "\n",
        "status = []\n",
        "for i in range(0, len(video_ids), 40):\n",
        "  res = (youtube).videos().list(id=','.join(video_ids[i:i+40]),part='status').execute()\n",
        "  status += res['items']\n",
        "print(status)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuGWfkwTImnh"
      },
      "source": [
        "print(stats[0])\n",
        "print(contents[0])\n",
        "print(status[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkxRu5KyLz5W"
      },
      "source": [
        "Now we will retrieved the complete details of all videos individually uploaded on the channel- youtube and will save in dataframe as csv file.<br>\n",
        "including the:\n",
        "* videoTitle\n",
        "* videoID\n",
        "* likedCount\n",
        "* dislikedCount\n",
        "* viewCount\n",
        "* commentCount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRfIDoF6MyrH"
      },
      "source": [
        "title=[]\n",
        "liked=[]\n",
        "disliked=[]\n",
        "views=[]\n",
        "url=[]\n",
        "comment=[]\n",
        "videoid = []\n",
        "publishedDate = []\n",
        "video_description = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn43xhvXJaE-"
      },
      "source": [
        "for i in range(0,len(allVideos)):\n",
        "  # print(i)\n",
        "  i += 1\n",
        "  try:\n",
        "    title.append((allVideos[i])['snippet']['title'])\n",
        "  except:\n",
        "    title.append(0)\n",
        "  \n",
        "  try:\n",
        "    publishedDate.append((allVideos[i])['snippet']['publishedAt'])\n",
        "  except:\n",
        "    publishedDate.append(0)\n",
        "  \n",
        "  try:\n",
        "    video_description.append((allVideos[i])['snippet']['description'])\n",
        "  except:\n",
        "    video_description.append(0)\n",
        "  try:\n",
        "    liked.append(int((stats[i])['statistics']['likeCount']))\n",
        "  except:\n",
        "    liked.append(0)\n",
        "  try:\n",
        "    disliked.append(int((stats[i])['statistics']['dislikeCount']))\n",
        "  except:\n",
        "    disliked.append(0)\n",
        "  try:\n",
        "    views.append(int((stats[i])['statistics']['viewCount']))\n",
        "  except:\n",
        "    views.append(0)\n",
        "  try:\n",
        "    comment.append(int((stats[i])['statistics']['commentCount']))\n",
        "  except:\n",
        "    comment.append(0)\n",
        "  try:\n",
        "    videoid.append(allVideos[i]['id']['videoId'])\n",
        "  except:\n",
        "    videoid.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrrOJ7GrJq2w"
      },
      "source": [
        "import pandas as pd\n",
        "data={'title':title,'videoIds':videoid,'video_description':video_description,'publishedDate':publishedDate,'likes':liked,'dislikes':disliked,'views':views,'comment':comment}\n",
        "df=pd.DataFrame(data)\n",
        "# df.sort_values(by=['videoIds'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YUGvHeURY-Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "b5bfd337-92cf-4463-a97b-a6aa9007f22c"
      },
      "source": [
        "vidFile = 'Youtube_Videos_' + str(datetime.datetime.now()).replace(' ','_') + '.csv'\n",
        "df.to_csv(vidFile,index = False)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(vidFile)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-91e0a40fe513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvidFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Youtube_Videos_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvidFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvidFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYP8yP_WGtQi"
      },
      "source": [
        "def get_comments(youtube, videoId, maxResults, pageToken):\n",
        "  try:\n",
        "\n",
        "    result = youtube.commentThreads().list(\n",
        "      part=\"snippet\",\n",
        "      videoId=videoId,\n",
        "      pageToken=pageToken,\n",
        "      order=\"relevance\",\n",
        "      textFormat=\"plainText\",\n",
        "      maxResults=maxResults\n",
        "    ).execute()\n",
        "  except:\n",
        "    print(\"error\")\n",
        "    result={}\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vUJjEn2G9ha"
      },
      "source": [
        "comments = []\n",
        "for i, vi in enumerate(allVideos):\n",
        "    #print(i)\n",
        "    #print(vi)\n",
        "    # print(\"%s: %d\" % (channel[\"name\"], i))\n",
        "    videoId = vi[\"id\"][\"videoId\"]\n",
        "    pageToken = None\n",
        "    for _ in range(4):\n",
        "      if pageToken != False:\n",
        "        resultComments = get_comments(youtube, videoId, 100, pageToken)\n",
        "        comments.extend(resultComments.get(\"items\", []))\n",
        "        pageToken = resultComments.get(\"nextPageToken\", False)\n",
        "\n",
        "comments[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv3ajXCrIJur"
      },
      "source": [
        "print(len(comments))\n",
        "# print(comments[0][\"snippet\"][\"topLevelComment\"][\"snippet\"])\n",
        "# print(comments[0][\"snippet\"][\"videoId\"],comments[0][\"snippet\"][\"topLevelComment\"][\"id\"])\n",
        "# print(comments[0][\"snippet\"][\"topLevelComment\"][\"id\"],comments[0][\"snippet\"][\"topLevelComment\"][\"snippet\"][\"authorDisplayName\"],\n",
        "# comments[0][\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"],comments[0][\"snippet\"][\"totalReplyCount\"],\n",
        "# comments[0][\"snippet\"][\"topLevelComment\"][\"snippet\"][\"likeCount\"],comments[0][\"snippet\"][\"topLevelComment\"][\"snippet\"][\"publishedAt\"])\n",
        "\n",
        "# clc = []\n",
        "video_id_com = []\n",
        "toplevel = []\n",
        "author = []\n",
        "textcomm = []\n",
        "totReplyCount = []\n",
        "likeCount = []\n",
        "publishedAt = []\n",
        "error = 'error'\n",
        "\n",
        "\n",
        "for i in range(0,len(comments)-1):\n",
        "  # print(i)\n",
        "  i += 1\n",
        "\n",
        "  # try:\n",
        "  #   clc.append(comment[i][\"snippet\"][\"topLevelComment\"][\"snippet\"])\n",
        "  # except:\n",
        "  #   clc.append(None)\n",
        "  #   print(error)\n",
        "\n",
        "  try:\n",
        "    video_id_com.append(comments[i][\"snippet\"][\"videoId\"])\n",
        "  except:\n",
        "    video_id_com.append(None)\n",
        "    print('7'+error)\n",
        "\n",
        "  try:\n",
        "    toplevel.append(comments[i][\"snippet\"][\"topLevelComment\"][\"id\"])\n",
        "  except:\n",
        "    toplevel.append(None)\n",
        "    print('6'+error)\n",
        "\n",
        "  try:\n",
        "    author.append(comments[i][\"snippet\"][\"topLevelComment\"][\"snippet\"][\"authorDisplayName\"])\n",
        "  except:\n",
        "    author.append(None)\n",
        "    print('5'+error)\n",
        "\n",
        "  try:\n",
        "    textcomm.append(comments[i][\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"])\n",
        "  except:\n",
        "    textcomm.append(None)\n",
        "    print('4'+error)\n",
        "\n",
        "  try:\n",
        "    totReplyCount.append(comments[i][\"snippet\"][\"totalReplyCount\"])\n",
        "  except:\n",
        "    totReplyCount.append(0)\n",
        "    print('3'+error)\n",
        "\n",
        "  try:\n",
        "    likeCount.append(comments[i][\"snippet\"][\"topLevelComment\"][\"snippet\"][\"likeCount\"])\n",
        "  except:\n",
        "    likeCount.append(0)\n",
        "    print('2'+error)\n",
        "\n",
        "  try:\n",
        "    publishedAt.append(comments[i][\"snippet\"][\"topLevelComment\"][\"snippet\"][\"publishedAt\"])\n",
        "  except:\n",
        "    publishedAt.append(0)\n",
        "    print('1'+error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myRC912mKa3b"
      },
      "source": [
        "data1={'videoIds':video_id_com,'topLevelComment':toplevel,'authorDisplayName':author,'textDisplay':textcomm,\n",
        "      'totalReplyCount':totReplyCount,'likes':likeCount,'publishedAt':publishedAt}\n",
        "df1=pd.DataFrame(data1)\n",
        "# df.sort_values(by=['videoIds'])\n",
        "df1.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvva3e7qPoUa"
      },
      "source": [
        "commFile = 'Youtube_Videos_Comments' + str(datetime.datetime.now()).replace(' ','_') + '.csv'\n",
        "df1.to_csv(commFile,index = False)\n",
        "files.download(commFile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzO79VcSrYL8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6F7BJv3SFJn"
      },
      "source": [
        "# Load in the dataframe\n",
        "# df = pd.read_csv(\"data/winemag-data-130k-v2.csv\", index_col=0)\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGDWWuCRtcKK"
      },
      "source": [
        "df2 = pd.merge(df, df1, on='videoIds', how='outer')\n",
        "\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTXEIeexsUOp"
      },
      "source": [
        "print(\"There are {} observations and {} features in this dataset. \\n\".format(df2.shape[0],df2.shape[1]))\n",
        "\n",
        "print(\"There are {} videos in this dataset such as {}... \\n\".format(len(df2.videoIds.unique()),\n",
        "                                                                           \", \".join(df2.videoIds.unique()[0:5])))\n",
        "\n",
        "print(\"There are {} comments in this dataset such as {}... \\n\".format(len(df2.textDisplay.unique()),\n",
        "                                                                                      \", \".join(df2.textDisplay.unique()[0:5])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVTechQ9sht-"
      },
      "source": [
        "?WordCloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb1MgTPqJjaG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciy943xavmu8"
      },
      "source": [
        "# Start with one review:\n",
        "text = df2.textDisplay[0]\n",
        "\n",
        "# Create and generate a word cloud image:\n",
        "wordcloud = WordCloud().generate(text)\n",
        "\n",
        "# Display the generated image:\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ovhtWknA16q"
      },
      "source": [
        "# comment_words = ''\n",
        "# stopwords = set(STOPWORDS)\n",
        "  \n",
        "# # iterate through the csv file\n",
        "# for val in df2.textDisplay:\n",
        "      \n",
        "#     # typecaste each val to string\n",
        "#     val = str(val)\n",
        "  \n",
        "#     # split the value\n",
        "#     tokens = val.split()\n",
        "      \n",
        "#     # Converts each token into lowercase\n",
        "#     for i in range(len(tokens)):\n",
        "#         tokens[i] = tokens[i].lower()\n",
        "      \n",
        "#     comment_words += \" \".join(tokens)+\" \"\n",
        "  \n",
        "# wordcloud = WordCloud(width = 800, height = 800,\n",
        "#                 background_color ='white',\n",
        "#                 stopwords = stopwords,\n",
        "#                 min_font_size = 10).generate(comment_words)\n",
        "  \n",
        "# # plot the WordCloud image                       \n",
        "# plt.figure(figsize = (8, 8), facecolor = None)\n",
        "# plt.imshow(wordcloud)\n",
        "# plt.axis(\"off\")\n",
        "# plt.tight_layout(pad = 0)\n",
        "  \n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7hSY9XKw8hG"
      },
      "source": [
        "wordcloud.to_file(\"first_review.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BpMrwL_xtHX"
      },
      "source": [
        "df2.textDisplay = np.where(df2.textDisplay.isnull(),'.',df2.textDisplay)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQFUeNGexIcZ"
      },
      "source": [
        "text = \" \".join(review for review in df2.textDisplay)\n",
        "print (\"There are {} words in the combination of all review.\".format(len(text)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La3qf_EKx-lE"
      },
      "source": [
        "# Create stopword list:\n",
        "stopwords = set(STOPWORDS)\n",
        "stopwords.update([\"sir\", \"video\", \"please\", \"really\", \"share\",\"please\", \"thanks\"])\n",
        "\n",
        "# Generate a word cloud image\n",
        "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
        "\n",
        "# Display the generated image:\n",
        "# the matplotlib way:\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo8ho_pDyg9B"
      },
      "source": [
        "wine_mask = np.array(Image.open(\"tools.png\"))\n",
        "wine_mask[110]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK6lKOrOzcAL"
      },
      "source": [
        "def transform_format(val):\n",
        "    if (val < 10).any():\n",
        "        return 0\n",
        "    else:\n",
        "        return 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWSwsX7Fzjru"
      },
      "source": [
        "# Transform your mask into a new one that will work with the function:\n",
        "transformed_wine_mask = np.ndarray((wine_mask.shape[0],wine_mask.shape[1]), np.int32)\n",
        "\n",
        "#transformed_wine_mask[transformed_wine_mask == 0] = 255\n",
        "\n",
        "for i in range(len(wine_mask)):\n",
        "  transformed_wine_mask[i] = list(map(transform_format, wine_mask[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH2Co9V9zki6"
      },
      "source": [
        "# Check the expected result of your mask\n",
        "transformed_wine_mask\n",
        "\n",
        "plt.figure(figsize=[20,10])\n",
        "plt.imshow(transformed_wine_mask)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tMsYr0-8fsT"
      },
      "source": [
        "# Create a word cloud image\n",
        "wc = WordCloud(background_color=\"white\", max_words=1000, \n",
        "               #mask=transformed_wine_mask,\n",
        "               stopwords=stopwords, contour_width=3, contour_color='firebrick')\n",
        "\n",
        "# Generate a wordcloud\n",
        "wc.generate(text)\n",
        "\n",
        "# store to file\n",
        "wc.to_file(\"tools1.png\")\n",
        "\n",
        "# show\n",
        "plt.figure(figsize=[20,18])\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}